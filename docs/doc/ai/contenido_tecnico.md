---
title: "Generaci√≥n de Contenido T√©cnico con LLMs"
description: "Automatizaci√≥n de documentaci√≥n, generaci√≥n de posts de blog y resumen de art√≠culos t√©cnicos usando Large Language Models"
date: 2026-01-25
tags: [ai, llm, documentation, automation, content-generation]
difficulty: intermediate
estimated_time: "30 min"
category: ai
status: published
prerequisites: ["ollama_basics", "chatbots_locales"]
---

# Generaci√≥n de Contenido T√©cnico con LLMs

> **Tiempo de lectura:** 30 minutos | **Dificultad:** Intermedia | **Categor√≠a:** Inteligencia Artificial

## Resumen

Los LLMs pueden automatizar la creaci√≥n de documentaci√≥n t√©cnica, generar posts de blog y resumir art√≠culos complejos. Esta gu√≠a cubre t√©cnicas pr√°cticas para usar modelos locales en workflows de documentaci√≥n empresarial, manteniendo calidad y consistencia.

## üéØ Por Qu√© Automatizar la Documentaci√≥n

### Problemas Comunes en Documentaci√≥n

- **Documentaci√≥n obsoleta:** C√≥digo cambia m√°s r√°pido que los docs
- **Inconsistencia de estilo:** M√∫ltiples autores, m√∫ltiples estilos
- **Falta de tiempo:** Developers prefieren codear que documentar
- **Barreras de idioma:** Contenido en un solo idioma limita audiencia

### Beneficios de LLMs para Documentaci√≥n

- ‚úÖ **Generaci√≥n autom√°tica** de docstrings y README
- ‚úÖ **Traducci√≥n t√©cnica** precisa a m√∫ltiples idiomas
- ‚úÖ **Resumen autom√°tico** de PRs y changelogs
- ‚úÖ **Consistencia de estilo** con templates personalizados
- ‚úÖ **Actualizaci√≥n continua** con CI/CD integration

## üìù Caso de Uso 1: Generaci√≥n de Documentaci√≥n API

### Automatizaci√≥n de Docstrings

```python
import ast
import requests

def generate_docstring(function_code: str, model: str = "llama2:7b-chat-q4_0") -> str:
    """
    Genera un docstring profesional para una funci√≥n Python.
    
    Args:
        function_code: C√≥digo fuente de la funci√≥n
        model: Modelo Ollama a usar
        
    Returns:
        Docstring generado en formato Google Style
    """
    
    prompt = f"""
Eres un experto en documentaci√≥n Python. Genera un docstring profesional en formato Google Style para esta funci√≥n:

```python
{function_code}
```

El docstring debe incluir:
1. Descripci√≥n breve (1 l√≠nea)
2. Descripci√≥n detallada (si es necesario)
3. Args: con tipos y descripciones
4. Returns: con tipo y descripci√≥n
5. Raises: si aplica
6. Examples: c√≥digo de ejemplo

Responde SOLO con el docstring, sin explicaciones adicionales.
"""

    response = requests.post("http://localhost:11434/api/generate", json={
        "model": model,
        "prompt": prompt,
        "stream": False,
        "temperature": 0.3  # Baja temperatura para consistencia
    })
    
    if response.status_code == 200:
        return response.json()["response"].strip()
    else:
        raise Exception(f"Error generando docstring: {response.text}")

# Ejemplo de uso
code = """
def calculate_metrics(data: list, threshold: float = 0.5):
    filtered = [x for x in data if x > threshold]
    avg = sum(filtered) / len(filtered) if filtered else 0
    return {"count": len(filtered), "average": avg}
"""

docstring = generate_docstring(code)
print(docstring)
```

### Resultado Esperado

```python
"""
Calculate metrics for filtered data above a threshold.

Processes a list of numeric values, filters out values below the specified
threshold, and computes aggregated statistics.

Args:
    data (list): List of numeric values to process
    threshold (float, optional): Minimum value to include in calculations.
        Defaults to 0.5.

Returns:
    dict: Dictionary with keys:
        - 'count' (int): Number of values above threshold
        - 'average' (float): Mean of filtered values, or 0 if none

Examples:
    >>> calculate_metrics([0.3, 0.6, 0.8, 0.2], threshold=0.5)
    {'count': 2, 'average': 0.7}
    
    >>> calculate_metrics([0.1, 0.2], threshold=0.5)
    {'count': 0, 'average': 0}
"""
```

### Procesamiento por Lotes

```python
import os
import ast

def document_python_file(filepath: str, output_dir: str = "docs_generated"):
    """Documenta todas las funciones en un archivo Python."""
    
    with open(filepath, 'r') as f:
        tree = ast.parse(f.read())
    
    os.makedirs(output_dir, exist_ok=True)
    
    documented_functions = []
    
    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            # Extraer c√≥digo de la funci√≥n
            function_code = ast.get_source_segment(open(filepath).read(), node)
            
            # Generar docstring
            docstring = generate_docstring(function_code)
            
            documented_functions.append({
                "name": node.name,
                "docstring": docstring,
                "code": function_code
            })
    
    # Guardar documentaci√≥n en Markdown
    output_file = os.path.join(output_dir, f"{os.path.basename(filepath)}.md")
    with open(output_file, 'w') as f:
        f.write(f"# Documentaci√≥n: {filepath}\n\n")
        for func in documented_functions:
            f.write(f"## `{func['name']}`\n\n")
            f.write(f"```python\n{func['docstring']}\n```\n\n")
            f.write(f"**C√≥digo fuente:**\n```python\n{func['code']}\n```\n\n")
    
    print(f"‚úÖ Documentaci√≥n generada: {output_file}")
    return output_file

# Uso
document_python_file("my_module.py")
```

## üìÑ Caso de Uso 2: Generaci√≥n de README Autom√°tico

### Template con Variables

```python
from pathlib import Path
import json

def generate_readme(
    repo_path: str,
    project_name: str = None,
    description: str = None,
    model: str = "llama2:7b-chat-q4_0"
) -> str:
    """
    Genera un README.md profesional analizando el repositorio.
    
    Args:
        repo_path: Ruta al repositorio
        project_name: Nombre del proyecto (auto-detecta si None)
        description: Descripci√≥n breve (LLM genera si None)
        model: Modelo Ollama a usar
    
    Returns:
        Contenido del README.md generado
    """
    
    repo = Path(repo_path)
    
    # Auto-detectar informaci√≥n del proyecto
    if not project_name:
        project_name = repo.name
    
    # Analizar estructura
    files = list(repo.rglob("*.py"))
    has_tests = any("test" in str(f) for f in files)
    has_requirements = (repo / "requirements.txt").exists()
    has_docker = (repo / "Dockerfile").exists()
    
    # Leer archivos principales
    main_files = []
    for file in ["main.py", "app.py", "__init__.py", "setup.py"]:
        filepath = repo / file
        if filepath.exists():
            with open(filepath, 'r') as f:
                main_files.append({"name": file, "content": f.read()[:500]})
    
    # Prompt para LLM
    prompt = f"""
Genera un README.md profesional para este proyecto Python:

**Proyecto:** {project_name}
**Descripci√≥n:** {description or "Analiza el c√≥digo y genera una descripci√≥n"}
**Estructura:**
- {len(files)} archivos Python
- Tests: {"S√≠" if has_tests else "No"}
- Docker: {"S√≠" if has_docker else "No"}

**Archivos principales:**
{json.dumps(main_files, indent=2)}

Genera un README con estas secciones:
1. # {project_name} - T√≠tulo y badges
2. ## Descripci√≥n - Qu√© hace el proyecto (2-3 p√°rrafos)
3. ## Caracter√≠sticas - Lista de features principales
4. ## Requisitos - Python version, dependencias
5. ## Instalaci√≥n - Paso a paso
6. ## Uso - Ejemplos b√°sicos
7. ## Desarrollo - C√≥mo contribuir
8. ## Licencia

Usa formato Markdown profesional. S√© conciso pero completo.
"""

    response = requests.post("http://localhost:11434/api/generate", json={
        "model": model,
        "prompt": prompt,
        "stream": False,
        "temperature": 0.4
    })
    
    if response.status_code == 200:
        readme_content = response.json()["response"]
        
        # Guardar README
        with open(repo / "README.md", 'w') as f:
            f.write(readme_content)
        
        print(f"‚úÖ README generado en {repo / 'README.md'}")
        return readme_content
    else:
        raise Exception(f"Error: {response.text}")

# Uso
readme = generate_readme(
    "/path/to/my-project",
    description="API REST para gesti√≥n de usuarios con autenticaci√≥n JWT"
)
```

## ‚úçÔ∏è Caso de Uso 3: Generaci√≥n de Posts de Blog

### Pipeline Completo

```python
from datetime import datetime
import frontmatter

class BlogPostGenerator:
    def __init__(self, model: str = "llama2:13b-chat-q4_0"):
        self.model = model
        self.ollama_url = "http://localhost:11434/api/generate"
    
    def generate_outline(self, topic: str, audience: str = "developers") -> list:
        """Genera un outline estructurado para el post."""
        
        prompt = f"""
Crea un outline detallado para un post de blog t√©cnico sobre: {topic}

Audiencia: {audience}
Objetivo: Educativo, pr√°ctico, con ejemplos de c√≥digo

Genera una estructura con:
1. T√≠tulo atractivo (H1)
2. Introducci√≥n (problema que resuelve)
3. 4-5 secciones principales (H2) con subsecciones (H3)
4. Secci√≥n de conclusiones
5. Referencias/recursos

Formato: Lista con vi√±etas, indicando nivel de heading.
"""
        
        response = requests.post(self.ollama_url, json={
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "temperature": 0.6
        })
        
        outline_text = response.json()["response"]
        # Parsear outline a estructura
        return self._parse_outline(outline_text)
    
    def generate_section(self, section_title: str, context: str = "") -> str:
        """Genera contenido para una secci√≥n espec√≠fica."""
        
        prompt = f"""
Escribe la secci√≥n "{section_title}" de un post t√©cnico.

Contexto del art√≠culo: {context}

Requisitos:
- 300-500 palabras
- Incluir ejemplos de c√≥digo si es relevante
- Tono profesional pero accesible
- Formato Markdown
- Incluir enlaces a recursos externos si aplica

Contenido:
"""
        
        response = requests.post(self.ollama_url, json={
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "temperature": 0.7
        })
        
        return response.json()["response"]
    
    def generate_full_post(
        self,
        topic: str,
        tags: list,
        category: str = "DevOps",
        audience: str = "developers"
    ) -> str:
        """Genera un post completo de blog."""
        
        # 1. Generar outline
        print("üìù Generando outline...")
        outline = self.generate_outline(topic, audience)
        
        # 2. Generar cada secci√≥n
        print("‚úçÔ∏è  Generando secciones...")
        sections = []
        for item in outline:
            section_content = self.generate_section(
                item["title"],
                context=f"Post sobre {topic}"
            )
            sections.append({
                "level": item["level"],
                "title": item["title"],
                "content": section_content
            })
        
        # 3. Ensamblar post completo
        print("üîß Ensamblando post...")
        post_content = self._assemble_post(sections)
        
        # 4. Agregar frontmatter
        post = frontmatter.Post(post_content)
        post.metadata = {
            "title": outline[0]["title"] if outline else topic,
            "date": datetime.now().strftime("%Y-%m-%d"),
            "tags": tags,
            "category": category,
            "author": "AI Assistant",
            "draft": True  # Revisar antes de publicar
        }
        
        # 5. Guardar
        filename = f"blog_{datetime.now().strftime('%Y%m%d')}_{topic.lower().replace(' ', '_')}.md"
        with open(filename, 'w') as f:
            f.write(frontmatter.dumps(post))
        
        print(f"‚úÖ Post generado: {filename}")
        return filename
    
    def _parse_outline(self, text: str) -> list:
        """Parsea texto de outline a estructura."""
        # Implementaci√≥n simplificada
        lines = text.strip().split('\n')
        outline = []
        for line in lines:
            if line.startswith('#'):
                level = len(line.split()[0])
                title = line.lstrip('#').strip()
                outline.append({"level": level, "title": title})
        return outline
    
    def _assemble_post(self, sections: list) -> str:
        """Ensambla secciones en post completo."""
        content = []
        for section in sections:
            heading = '#' * section["level"]
            content.append(f"{heading} {section['title']}\n\n{section['content']}\n\n")
        return '\n'.join(content)

# Uso
generator = BlogPostGenerator()
post_file = generator.generate_full_post(
    topic="Optimizaci√≥n de Kubernetes en Producci√≥n",
    tags=["kubernetes", "devops", "performance"],
    category="Infrastructure"
)
```

## üìä Caso de Uso 4: Resumen de Art√≠culos T√©cnicos

### Resumen Inteligente con Extracci√≥n de Conceptos

```python
import requests
from bs4 import BeautifulSoup

class TechnicalSummarizer:
    def __init__(self, model: str = "llama2:13b-chat-q4_0"):
        self.model = model
        self.ollama_url = "http://localhost:11434/api/generate"
    
    def fetch_article(self, url: str) -> dict:
        """Extrae contenido de un art√≠culo web."""
        response = requests.get(url)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Extraer t√≠tulo y contenido principal
        title = soup.find('h1').get_text() if soup.find('h1') else "Sin t√≠tulo"
        
        # Remover scripts y estilos
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Extraer texto
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = ' '.join(chunk for chunk in chunks if chunk)
        
        return {"title": title, "content": text[:4000]}  # Limitar a 4k chars
    
    def summarize(
        self,
        text: str,
        summary_type: str = "executive",  # executive, technical, bullet_points
        max_length: int = 500
    ) -> str:
        """Genera resumen del texto."""
        
        prompts = {
            "executive": f"""
Resume este art√≠culo t√©cnico en {max_length} palabras para ejecutivos no t√©cnicos.
Enf√≥cate en: problema, soluci√≥n, beneficios, impacto de negocio.

Art√≠culo:
{text}

Resumen ejecutivo:
""",
            "technical": f"""
Resume este art√≠culo t√©cnico en {max_length} palabras para desarrolladores.
Incluye: conceptos clave, arquitectura, implementaci√≥n, trade-offs.

Art√≠culo:
{text}

Resumen t√©cnico:
""",
            "bullet_points": f"""
Extrae los puntos clave de este art√≠culo t√©cnico (m√°ximo 10 puntos).
Formato: lista con vi√±etas, concisa y accionable.

Art√≠culo:
{text}

Puntos clave:
"""
        }
        
        prompt = prompts.get(summary_type, prompts["technical"])
        
        response = requests.post(self.ollama_url, json={
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "temperature": 0.3
        })
        
        return response.json()["response"]
    
    def extract_code_examples(self, text: str) -> list:
        """Extrae snippets de c√≥digo del texto."""
        
        prompt = f"""
Identifica y extrae TODOS los ejemplos de c√≥digo de este art√≠culo.
Para cada snippet, indica:
1. Lenguaje de programaci√≥n
2. Prop√≥sito/descripci√≥n breve
3. El c√≥digo completo

Texto:
{text}

Ejemplos de c√≥digo:
"""
        
        response = requests.post(self.ollama_url, json={
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "temperature": 0.2
        })
        
        return response.json()["response"]
    
    def generate_study_notes(self, url: str) -> dict:
        """Genera notas de estudio completas de un art√≠culo."""
        
        # 1. Fetch art√≠culo
        article = self.fetch_article(url)
        
        # 2. Generar diferentes res√∫menes
        executive = self.summarize(article["content"], "executive", 300)
        technical = self.summarize(article["content"], "technical", 500)
        bullet_points = self.summarize(article["content"], "bullet_points")
        
        # 3. Extraer c√≥digo
        code_examples = self.extract_code_examples(article["content"])
        
        # 4. Ensamblar notas
        notes = f"""# {article['title']}

## Resumen Ejecutivo
{executive}

## Resumen T√©cnico
{technical}

## Puntos Clave
{bullet_points}

## Ejemplos de C√≥digo
{code_examples}

---
*Fuente:* {url}
*Generado:* {datetime.now().strftime("%Y-%m-%d %H:%M")}
"""
        
        # 5. Guardar
        filename = f"notes_{datetime.now().strftime('%Y%m%d_%H%M')}.md"
        with open(filename, 'w') as f:
            f.write(notes)
        
        print(f"‚úÖ Notas generadas: {filename}")
        
        return {
            "executive": executive,
            "technical": technical,
            "bullet_points": bullet_points,
            "code_examples": code_examples,
            "filename": filename
        }

# Uso
summarizer = TechnicalSummarizer()
notes = summarizer.generate_study_notes("https://blog.example.com/kubernetes-optimization")
```

## üîÑ Caso de Uso 5: Changelog Autom√°tico desde Git

### Generaci√≥n de Release Notes

```python
import subprocess
import re

class ChangelogGenerator:
    def __init__(self, model: str = "llama2:7b-chat-q4_0"):
        self.model = model
        self.ollama_url = "http://localhost:11434/api/generate"
    
    def get_commits_since_tag(self, tag: str = None) -> list:
        """Obtiene commits desde el √∫ltimo tag."""
        
        if not tag:
            # Obtener √∫ltimo tag
            result = subprocess.run(
                ["git", "describe", "--tags", "--abbrev=0"],
                capture_output=True,
                text=True
            )
            tag = result.stdout.strip() if result.returncode == 0 else None
        
        # Obtener commits
        cmd = ["git", "log", f"{tag}..HEAD", "--pretty=format:%H|%s|%b"] if tag else \
              ["git", "log", "--pretty=format:%H|%s|%b", "-20"]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        commits = []
        for line in result.stdout.split('\n'):
            if '|' in line:
                hash_id, subject, body = line.split('|', 2)
                commits.append({
                    "hash": hash_id[:7],
                    "subject": subject,
                    "body": body.strip()
                })
        
        return commits
    
    def categorize_commits(self, commits: list) -> dict:
        """Categoriza commits por tipo (feat, fix, docs, etc.)."""
        
        categories = {
            "features": [],
            "fixes": [],
            "docs": [],
            "refactor": [],
            "other": []
        }
        
        for commit in commits:
            subject = commit["subject"].lower()
            if subject.startswith("feat"):
                categories["features"].append(commit)
            elif subject.startswith("fix"):
                categories["fixes"].append(commit)
            elif subject.startswith("docs"):
                categories["docs"].append(commit)
            elif subject.startswith("refactor"):
                categories["refactor"].append(commit)
            else:
                categories["other"].append(commit)
        
        return categories
    
    def generate_changelog(
        self,
        version: str,
        since_tag: str = None,
        output_file: str = "CHANGELOG.md"
    ) -> str:
        """Genera changelog profesional."""
        
        # 1. Obtener commits
        commits = self.get_commits_since_tag(since_tag)
        
        # 2. Categorizar
        categorized = self.categorize_commits(commits)
        
        # 3. Generar descripci√≥n con LLM
        prompt = f"""
Genera un changelog profesional para la versi√≥n {version} basado en estos commits:

**Features:**
{chr(10).join([f"- {c['subject']}" for c in categorized['features']])}

**Fixes:**
{chr(10).join([f"- {c['subject']}" for c in categorized['fixes']])}

**Docs:**
{chr(10).join([f"- {c['subject']}" for c in categorized['docs']])}

Requisitos:
1. Agrupa cambios relacionados
2. Usa lenguaje user-friendly (no t√©cnico)
3. Destaca breaking changes si los hay
4. Formato Markdown con secciones claras

Changelog:
"""
        
        response = requests.post(self.ollama_url, json={
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "temperature": 0.4
        })
        
        changelog_content = response.json()["response"]
        
        # 4. Agregar header
        full_changelog = f"""# Changelog

## [{version}] - {datetime.now().strftime("%Y-%m-%d")}

{changelog_content}

### Commits Incluidos
{chr(10).join([f"- {c['hash']} - {c['subject']}" for c in commits])}

"""
        
        # 5. Guardar
        with open(output_file, 'w') as f:
            f.write(full_changelog)
        
        print(f"‚úÖ Changelog generado: {output_file}")
        return full_changelog

# Uso
generator = ChangelogGenerator()
changelog = generator.generate_changelog(
    version="v2.1.0",
    since_tag="v2.0.0"
)
```

## üîß Integraci√≥n con CI/CD

### GitHub Actions Workflow

```yaml
name: Auto-generate Documentation

on:
  push:
    branches: [main]
  pull_request:

jobs:
  generate-docs:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.ai/install.sh | sh
          ollama pull llama2:7b-chat-q4_0
      
      - name: Install dependencies
        run: pip install requests python-frontmatter beautifulsoup4
      
      - name: Generate API docs
        run: python scripts/generate_docs.py --input src/ --output docs/api/
      
      - name: Generate changelog
        run: python scripts/generate_changelog.py --version {% raw %}${{ github.ref_name }}{% endraw %}
      
      - name: Commit changes
        run: |
          git config --global user.name 'Documentation Bot'
          git config --global user.email 'bot@example.com'
          git add docs/ CHANGELOG.md
          git commit -m "docs: Auto-generate documentation [skip ci]" || true
          git push
```

## ‚ö†Ô∏è Mejores Pr√°cticas

### Validaci√≥n de Contenido Generado

```python
class ContentValidator:
    def validate_markdown(self, content: str) -> dict:
        """Valida formato Markdown."""
        issues = []
        
        # Verificar headers
        if not re.search(r'^# ', content, re.MULTILINE):
            issues.append("Falta t√≠tulo principal (H1)")
        
        # Verificar enlaces rotos
        links = re.findall(r'\[([^\]]+)\]\(([^\)]+)\)', content)
        for text, url in links:
            if url.startswith('http'):
                try:
                    response = requests.head(url, timeout=5)
                    if response.status_code >= 400:
                        issues.append(f"Enlace roto: {url}")
                except:
                    issues.append(f"No se puede validar: {url}")
        
        return {
            "valid": len(issues) == 0,
            "issues": issues
        }
    
    def check_code_syntax(self, content: str) -> dict:
        """Valida sintaxis de bloques de c√≥digo."""
        code_blocks = re.findall(r'```(\w+)\n(.*?)\n```', content, re.DOTALL)
        issues = []
        
        for lang, code in code_blocks:
            if lang == "python":
                try:
                    compile(code, '<string>', 'exec')
                except SyntaxError as e:
                    issues.append(f"Error de sintaxis Python: {e}")
        
        return {
            "valid": len(issues) == 0,
            "issues": issues
        }

# Uso
validator = ContentValidator()
validation_result = validator.validate_markdown(generated_content)
if not validation_result["valid"]:
    print("‚ö†Ô∏è  Problemas encontrados:")
    for issue in validation_result["issues"]:
        print(f"  - {issue}")
```

### Control de Calidad

- ‚úÖ **Revisi√≥n humana** siempre antes de publicar
- ‚úÖ **Validaci√≥n de sintaxis** de c√≥digo generado
- ‚úÖ **Verificaci√≥n de enlaces** para evitar rotos
- ‚úÖ **Spell checking** con herramientas como `aspell`
- ‚úÖ **Tone consistency** validar con otro LLM

## üìä M√©tricas y Monitoreo

```python
class DocumentationMetrics:
    def __init__(self):
        self.metrics = {
            "documents_generated": 0,
            "total_words": 0,
            "total_cost_saved_hours": 0,
            "errors": 0
        }
    
    def record_generation(self, word_count: int, time_taken: float):
        self.metrics["documents_generated"] += 1
        self.metrics["total_words"] += word_count
        
        # Estimar ahorro (promedio 500 palabras/hora manual)
        hours_saved = word_count / 500
        self.metrics["total_cost_saved_hours"] += hours_saved
    
    def report(self):
        return f"""
üìä M√©tricas de Generaci√≥n de Documentaci√≥n

Documentos generados: {self.metrics['documents_generated']}
Palabras totales: {self.metrics['total_words']:,}
Horas ahorradas: {self.metrics['total_cost_saved_hours']:.1f}h
Errores: {self.metrics['errors']}
"""

metrics = DocumentationMetrics()
```

## üîó Recursos Adicionales

- [Ollama API Documentation](https://github.com/jmorganca/ollama/blob/main/docs/api.md)
- [MkDocs Material](https://squidfunk.github.io/mkdocs-material/)
- [Sphinx Documentation](https://www.sphinx-doc.org/)
- [Docusaurus](https://docusaurus.io/)

## üìö Pr√≥ximos Pasos

Despu√©s de automatizar documentaci√≥n, considera:

1. **[An√°lisis de Logs](analisis_logs.md)** - Troubleshooting asistido por IA
2. **[Prompt Engineering](prompt_engineering.md)** - T√©cnicas para mejores resultados
3. **[Fine-tuning](fine_tuning_basico.md)** - Personalizar modelos para tu dominio

---

*¬øHas automatizado tu documentaci√≥n con LLMs? Comparte tus experiencias y mejores pr√°cticas en los comentarios.*