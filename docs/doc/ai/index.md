# Inteligencia Artificial y LLMs

Esta secci贸n cubre el uso de Inteligencia Artificial, espec铆ficamente Large Language Models (LLMs), en entornos DevOps e infraestructura.

##  驴Qu茅 encontrar谩s aqu铆?

- **Fundamentos de LLMs**: Arquitectura, conceptos b谩sicos y casos de uso en DevOps
- **Herramientas locales**: Ollama, LM Studio, LLaMA.cpp para ejecutar modelos localmente
- **Integraci贸n con infraestructura**: Despliegue en Kubernetes, storage optimizado, networking
- **Metodolog铆as de testing**: Benchmarks, evaluaci贸n y prompt engineering
- **Casos pr谩cticos**: Chatbots, an谩lisis de logs, automatizaci贸n IaC

##  Inicio r谩pido

Si eres nuevo en LLMs, comienza con:
1. [Introducci贸n a LLMs](llms_fundamentals.md) - Conceptos b谩sicos
2. [Ollama: primeros pasos](ollama_basics.md) - Tu primera instalaci贸n
3. [Evaluaci贸n de modelos](model_evaluation.md) - C贸mo medir rendimiento

##  Contenido principal

### Fundamentos
- [Introducci贸n a LLMs](llms_fundamentals.md)

### Herramientas
- [Ollama](ollama_basics.md)

### Testing y evaluaci贸n
- [Evaluaci贸n de modelos](model_evaluation.md)

##  Enlaces relacionados

- [Documentaci贸n de Ollama](https://github.com/ollama/ollama)
- [LM Studio](https://lmstudio.ai/)
- [LLaMA.cpp](https://github.com/ggerganov/llama.cpp)
- [vLLM](https://github.com/vllm-project/vllm)