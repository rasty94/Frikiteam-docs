# Artificial Intelligence and LLMs

This section covers the use of Artificial Intelligence, specifically Large Language Models (LLMs), in DevOps and infrastructure environments.

## ðŸ¤– What you'll find here

- **LLM Fundamentals**: Architecture, basic concepts and DevOps use cases
- **Local tools**: Ollama, LM Studio, LLaMA.cpp for running models locally
- **Infrastructure integration**: Kubernetes deployment, optimized storage, networking
- **Testing methodologies**: Benchmarks, evaluation and prompt engineering
- **Practical cases**: Chatbots, log analysis, IaC automation

## ðŸš€ Quick start

If you're new to LLMs, start with:
1. [Introduction to LLMs](llms_fundamentals.md) - Basic concepts
2. [Ollama: getting started](ollama_basics.md) - Your first installation
3. [Model evaluation](model_evaluation.md) - How to measure performance

## ðŸ“š Main content

### Fundamentals
- [LLMs Introduction](llms_fundamentals.md)

### Tools
- [Ollama](ollama_basics.md)

### Testing and evaluation
- [Model evaluation](model_evaluation.md)

## ðŸ”— Related links

- [Ollama Documentation](https://github.com/ollama/ollama)
- [LM Studio](https://lmstudio.ai/)
- [LLaMA.cpp](https://github.com/ggerganov/llama.cpp)
- [vLLM](https://github.com/vllm-project/vllm)